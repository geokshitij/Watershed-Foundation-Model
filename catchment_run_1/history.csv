epoch,train_loss,val_loss
1,1532.8197021484375,816.3048706054688
2,815.8707275390625,602.42822265625
3,602.36279296875,510.2668151855469
4,510.4893798828125,456.65911865234375
5,456.6203308105469,422.9737854003906
6,423.0443420410156,400.0597839355469
7,399.9645080566406,382.181884765625
8,382.1849365234375,367.9632873535156
9,368.027587890625,357.0357666015625
10,357.1446228027344,348.77850341796875
11,348.7735595703125,341.9587097167969
12,341.90753173828125,336.1128845214844
13,336.1882629394531,331.2087707519531
14,331.1746520996094,327.07330322265625
15,326.9986267089844,323.5147399902344
16,323.5233459472656,320.5858154296875
17,320.56854248046875,318.19281005859375
18,318.2111511230469,316.0963134765625
19,316.0694580078125,314.1934509277344
20,314.3294677734375,312.4827880859375
21,312.453125,310.79815673828125
22,310.8410339355469,309.05426025390625
23,308.9546203613281,307.2197570800781
24,307.1954040527344,305.2434387207031
25,304.9151306152344,302.70587158203125
26,302.75860595703125,299.98907470703125
27,299.9092712402344,296.7073974609375
28,296.6904296875,292.55535888671875
29,292.7768249511719,288.125244140625
30,288.23809814453125,283.75628662109375
31,283.2453308105469,277.28564453125
32,277.17279052734375,271.0240783691406
33,271.47332763671875,265.018798828125
34,263.66455078125,259.2087097167969
35,258.0091552734375,250.45106506347656
36,251.178466796875,248.73861694335938
37,249.15098571777344,244.90675354003906
38,246.03720092773438,241.07586669921875
39,242.46922302246094,233.5502471923828
40,232.77099609375,225.040771484375
41,228.38108825683594,218.78652954101562
42,222.73158264160156,216.99160766601562
43,213.9252166748047,208.84542846679688
44,207.29409790039062,209.88111877441406
45,212.12049865722656,200.1382293701172
46,204.55030822753906,195.66195678710938
47,200.47972106933594,191.89273071289062
48,194.46450805664062,190.55792236328125
49,190.7671356201172,187.5599822998047
50,187.22515869140625,186.73663330078125
